{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c2db1e2-629e-4081-9600-e609276946e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import re\n",
    "from typing import List\n",
    "from dotenv import load_dotenv\n",
    "from llama_index.multi_modal_llms.openai import OpenAIMultiModal\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from pydantic import BaseModel, Field\n",
    "from engine import StandarOpenAIBuilder\n",
    "from llama_index.core.query_pipeline import QueryPipeline\n",
    "from llama_index.core import PromptTemplate\n",
    "from llama_index.core.schema import TextNode\n",
    "from llama_index.core.schema import ImageDocument\n",
    "from llama_index.core.indices import MultiModalVectorStoreIndex\n",
    "from llama_index.vector_stores.pinecone import PineconeVectorStore\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "from llama_index.core import Settings, StorageContext, VectorStoreIndex\n",
    "from fitz import open as fitz_open\n",
    "from llama_index.core import SimpleDirectoryReader\n",
    "from llama_index.core import load_index_from_storage\n",
    "\n",
    "from llama_index.core.vector_stores import MetadataInfo, VectorStoreInfo\n",
    "from llama_index.core.indices.multi_modal.retriever import (\n",
    "    MultiModalVectorIndexRetriever,\n",
    ")\n",
    "from llama_index.core.response.notebook_utils import display_source_node\n",
    "from llama_index.core.schema import ImageNode\n",
    "from IPython.display import Image\n",
    "from llama_index.core.vector_stores import (\n",
    "    MetadataFilter,\n",
    "    MetadataFilters,\n",
    "    FilterOperator,\n",
    ")\n",
    "from llama_index.core.schema import MetadataMode\n",
    "from llama_index.core import QueryBundle\n",
    "from llama_index.core.schema import NodeWithScore\n",
    "\n",
    "load_dotenv(override=True)\n",
    "\n",
    "PINECONE_API_KEY = os.getenv(\"PINECONE_API_KEY\")\n",
    "\n",
    "store_path = \"data\"\n",
    "temp_path = \"data/temp\"\n",
    "index_name_text = \"text-index\"\n",
    "index_name_image = \"images-index\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "30685665-7ae5-4562-a009-fa17c98ca83e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_pdf(pdf_path):\n",
    "    \"\"\"\n",
    "    Processes a PDF file and extracts each page as an image.\n",
    "\n",
    "    Args:\n",
    "        pdf_path (str): The path to the PDF file to be processed.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "\n",
    "    This function performs the following steps:\n",
    "    1. Opens the PDF file using the `fitz_open` function.\n",
    "    2. Extracts the file name from the given PDF path.\n",
    "    3. Creates a directory to store the extracted images if it does not already exist.\n",
    "    4. Iterates through each page of the PDF document.\n",
    "    5. Converts each page to an image using the `get_pixmap` method.\n",
    "    6. Saves each image as a PNG file in the created directory.\n",
    "    7. Closes the PDF document.\n",
    "    \"\"\"\n",
    "    pdf_document = fitz_open(pdf_path)\n",
    "    file_name = pdf_path.split(\"/\")[-1].split(\".\")[0]\n",
    "    if not os.path.exists(f\"./{store_path}/temp/{file_name}\"):\n",
    "        os.makedirs(f\"./{store_path}/temp/{file_name}\")\n",
    "\n",
    "    for page_number in range(pdf_document.page_count):\n",
    "        page = pdf_document[page_number]\n",
    "        pix = page.get_pixmap()\n",
    "        image_array = np.frombuffer(pix.samples, dtype=np.uint8).reshape(\n",
    "            pix.height, pix.width, 3\n",
    "        )\n",
    "        cv2.imwrite(\n",
    "            f\"./{store_path}/temp/{file_name}/{file_name}_{page_number + 1}.png\",\n",
    "            image_array,\n",
    "        )\n",
    "    pdf_document.close()\n",
    "\n",
    "def parse_pdf_folder(pdf_folder):\n",
    "    \"\"\"\n",
    "    Parses a folder containing PDF files and processes each PDF.\n",
    "\n",
    "    Args:\n",
    "        pdf_folder (str): The path to the folder containing PDF files.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    pdfs = [f for f in os.listdir(pdf_folder) if f.endswith(\".pdf\")]\n",
    "    for pdf in pdfs:\n",
    "        process_pdf(f\"{pdf_folder}/{pdf}\")\n",
    "\n",
    "def init_pinecone():\n",
    "    \"\"\"\n",
    "    Initializes and configures Pinecone indexes for text and image data.\n",
    "\n",
    "    This function performs the following steps:\n",
    "    1. Creates a Pinecone client using the provided API key.\n",
    "    2. Lists existing indexes in Pinecone.\n",
    "    3. Checks if the specified text and image indexes exist; if not, creates them with the specified dimensions and metrics.\n",
    "    4. Initializes Pinecone indexes for text and image data.\n",
    "    5. Creates PineconeVectorStore instances for text and image data.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing two PineconeVectorStore instances:\n",
    "            - text_store: The PineconeVectorStore instance for text data.\n",
    "            - image_store: The PineconeVectorStore instance for image data.\n",
    "    \"\"\"\n",
    "    pc = Pinecone(api_key=PINECONE_API_KEY)\n",
    "    pc_list = pc.list_indexes()\n",
    "    if not any(index_name_text == idx[\"name\"] for idx in pc_list.indexes):\n",
    "        pc.create_index(\n",
    "            name=index_name_text,\n",
    "            dimension=1536,\n",
    "            metric=\"dotproduct\",\n",
    "            spec=ServerlessSpec(cloud=\"aws\", region=\"us-east-1\"),\n",
    "        )\n",
    "    if not any(index_name_image == idx[\"name\"] for idx in pc_list.indexes):\n",
    "        pc.create_index(\n",
    "            name=index_name_image,\n",
    "            dimension=512,\n",
    "            metric=\"dotproduct\",\n",
    "            spec=ServerlessSpec(cloud=\"aws\", region=\"us-east-1\"),\n",
    "        )\n",
    "\n",
    "    pinecone_index_text = pc.Index(index_name_text)\n",
    "    pinecone_index_image = pc.Index(index_name_image)\n",
    "    image_store = PineconeVectorStore(\n",
    "        pinecone_index=pinecone_index_image, index_name=index_name_text\n",
    "    )\n",
    "    text_store = PineconeVectorStore(\n",
    "        pinecone_index=pinecone_index_text, index_name=index_name_text\n",
    "    )\n",
    "    return text_store, image_store\n",
    "\n",
    "\n",
    "\n",
    "def ingest_data(documents, text_store, image_store):\n",
    "    \"\"\"\n",
    "    Ingests data into a multi-modal vector store index and persists the storage context.\n",
    "\n",
    "    Args:\n",
    "        documents (list): A list of documents to be ingested.\n",
    "        text_store (VectorStore): The vector store for text data.\n",
    "        image_store (ImageStore): The image store for image data.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing the created MultiModalVectorStoreIndex and the StorageContext.\n",
    "    \"\"\"\n",
    "    storage_context = StorageContext.from_defaults(\n",
    "        vector_store=text_store, image_store=image_store\n",
    "    )\n",
    "\n",
    "    index = MultiModalVectorStoreIndex.from_documents(\n",
    "        documents=documents,\n",
    "        storage_context=storage_context,\n",
    "        store_nodes_override=True,\n",
    "    )\n",
    "    index.storage_context.persist(persist_dir=\"./storage\")\n",
    "    return index, storage_context\n",
    "\n",
    "\n",
    "def load_index_from_storage_folder(text_store, image_store):\n",
    "    \"\"\"\n",
    "    Load an index from the specified storage folder.\n",
    "\n",
    "    This function initializes a storage context using the provided text store\n",
    "    and a default persistence directory. It then loads an index from the storage\n",
    "    context and the provided image store.\n",
    "\n",
    "    Args:\n",
    "        text_store (str): The path or identifier for the text storage.\n",
    "        image_store (str): The path or identifier for the image storage.\n",
    "\n",
    "    Returns:\n",
    "        Index: The loaded index from the storage.\n",
    "    \"\"\"\n",
    "    storage_context = StorageContext.from_defaults(\n",
    "        vector_store=text_store, persist_dir=\"./storage\"\n",
    "    )\n",
    "    index = load_index_from_storage(storage_context, image_store=image_store)\n",
    "    return index\n",
    "\n",
    "\n",
    "# TODO: Extract more metadata as summary, title, etc. So wa can also have more information in the metadata\n",
    "def get_meta(file_path):\n",
    "    \"\"\"\n",
    "    Extracts metadata from a given file path.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): The path to the file.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing the file path, item part, and page part.\n",
    "\n",
    "    Raises:\n",
    "        ValueError: If the file_path is not a string.\n",
    "        ValueError: If the file name format is incorrect.\n",
    "    \"\"\"\n",
    "    if not isinstance(file_path, str):\n",
    "        raise ValueError(\"file_name must be a string\")\n",
    "\n",
    "    file_name = os.path.basename(file_path)\n",
    "    pattern = re.compile(r\"^[a-zA-Z0-9-]+__[a-zA-Z0-9--]+_\\d+\\.[a-zA-Z0-9]+$\")\n",
    "    if not pattern.match(file_name):\n",
    "        raise ValueError(\"file name format is incorrect\")\n",
    "\n",
    "    try:\n",
    "        item_part = file_name.split(\"__\")[0]\n",
    "        page_part = file_path.split(\"_\")[-1].split(\".\")[0]\n",
    "        return {\n",
    "            \"file_path\": file_path,\n",
    "            \"item\": item_part,\n",
    "            \"page\": page_part,\n",
    "        }\n",
    "    except (IndexError, ValueError):\n",
    "        raise ValueError(\"file name format is incorrect\")\n",
    "\n",
    "def display_response(nodes: List[TextNode]):\n",
    "    \"\"\"\n",
    "    Display the content of each TextNode in the provided list.\n",
    "\n",
    "    Args:\n",
    "        nodes (List[TextNode]): A list of TextNode objects to display.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    \"\"\"Display response.\"\"\"\n",
    "    for node in nodes:\n",
    "        print(node.get_content(metadata_mode=\"all\"))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f80d4827-cf78-428a-a302-df6f08a1820c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/d6/ltq_22dn5fd4p1z6r5kmwsl4jpfd5x/T/ipykernel_11663/3539252859.py:162: FutureWarning: Possible set difference at position 26\n",
      "  pattern = re.compile(r\"^[a-zA-Z0-9-]+__[a-zA-Z0-9--]+_\\d+\\.[a-zA-Z0-9]+$\")\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "415f7b40cd604c8b8f5cc39755d0cdf6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upserted vectors:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "vector_store_info = VectorStoreInfo(\n",
    "    content_info=\"Manuals\",\n",
    "    metadata_info=[\n",
    "        MetadataInfo(\n",
    "            name=\"item\",\n",
    "            description=\"Item of the ikea manual.\",\n",
    "            type=\"string\",\n",
    "        ),\n",
    "        MetadataInfo(\n",
    "            name=\"file_path\",\n",
    "            description=\"File path of the image of the manual\",\n",
    "            type=\"string\",\n",
    "        ),\n",
    "    ],\n",
    ")\n",
    "\n",
    "\n",
    "engine = StandarOpenAIBuilder()\n",
    "text_store, image_store = init_pinecone()\n",
    "parse_pdf_folder(store_path)\n",
    "documents = SimpleDirectoryReader(\n",
    "    input_dir=temp_path, filename_as_id=True, recursive=True, file_metadata=get_meta\n",
    ").load_data()\n",
    "\n",
    "index, store_context = ingest_data(documents, text_store, image_store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3d0e1fd2-2593-45df-bc60-3e2334a44661",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retriever_custom(\n",
    "        query: str = Field(\n",
    "          description=\"Original query from the user, should be always the original one\",\n",
    "          examples=[\"Which ones are the tools of the tuffle furniture?\"]\n",
    "        ),\n",
    "        filter_entinty: str = Field(\n",
    "          description=\"The primary entity the user is inquiring about, typically the item for which they need instructions from the manual. Must be in lowercase and just one word\",\n",
    "          examples=[\"tuffle\"]\n",
    "        ),\n",
    "        return_images: bool = False\n",
    "    ):\n",
    "    \"\"\"\n",
    "    Retrieves relevant images and generates a response based on the provided query and filter entity.\n",
    "    Args:\n",
    "        query (str): Original query from the user, should be always the original one.\n",
    "            Example: \"Which ones are the tools of the tuffle furniture?\"\n",
    "        filter_entinty (str): The primary entity the user is inquiring about, typically the item for which they need instructions from the manual.\n",
    "            Must be in lowercase and just one word.\n",
    "            Example: \"tuffle\"\n",
    "    Returns:\n",
    "        tuple: A tuple containing the response from the language model and the retrieval results.\n",
    "    \"\"\"\n",
    "    retriever_engine = index.as_retriever(\n",
    "        similarity_top_k=3,\n",
    "        image_similarity_top_k=10,\n",
    "        vector_store_info=vector_store_info,\n",
    "        verbose=True,\n",
    "        filters=MetadataFilters(\n",
    "            filters=[\n",
    "                MetadataFilter(\n",
    "                    key=\"item\",\n",
    "                    operator=FilterOperator.EQ,\n",
    "                    value=filter_entinty,\n",
    "                ),\n",
    "            ]\n",
    "        ),\n",
    "    )\n",
    "    \n",
    "    assert isinstance(retriever_engine, MultiModalVectorIndexRetriever)\n",
    "    \n",
    "    retrieval_results = retriever_engine.text_to_image_retrieve(query)\n",
    "    retrieved_images = []\n",
    "    for res_node in retrieval_results:\n",
    "        if isinstance(res_node.node, ImageNode):\n",
    "            retrieved_images.append(res_node.node.metadata[\"file_path\"])\n",
    "        else:\n",
    "            print(display_source_node(res_node, source_length=200))\n",
    "    \n",
    "    \n",
    "    import matplotlib.pyplot as plt\n",
    "    from PIL import Image\n",
    "    \n",
    "    from llama_index.core.schema import ImageDocument\n",
    "    \n",
    "    image_documents = [\n",
    "        ImageDocument(image_path=image_path) for image_path in retrieved_images\n",
    "    ]\n",
    "    response = engine.llm.complete(\n",
    "        prompt=query,\n",
    "        image_documents=image_documents,\n",
    "    )\n",
    "    if return_images: \n",
    "        return response, retrieval_results\n",
    "    return response, []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "de68c55b-99ba-4b55-8260-fab0eabdb6a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only for evaluators for lack of time\n",
    "def extract_keyword_from_query(query):\n",
    "    llm = OpenAI()\n",
    "    json_prompt_str = \"\"\"\\\n",
    "        Please extract the entity that que question is referencing: {question}.  Retrieve only the single word of in \"minus\", the item brand, like 'fredy' or 'tuffing'. \n",
    "    \"\"\"\n",
    "    llm = OpenAI(model=\"gpt-3.5-turbo\")\n",
    "    json_prompt_tmpl = PromptTemplate(json_prompt_str)\n",
    "    p = QueryPipeline(\n",
    "        chain=[json_prompt_tmpl, llm],\n",
    "        verbose=True,\n",
    "    )\n",
    "    output = p.run(question=query)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "84cb4b49-b1ff-417d-80e3-5db5651e02fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_product_list():\n",
    "    with os.scandir(\"data\") as entries:\n",
    "        products = [entry.name for entry in entries if entry.is_file()]\n",
    "    print(products)\n",
    "    return \", \".join(products)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "661e9e37-eb93-4e7c-918d-5f9bc07bd2a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.tools import FunctionTool\n",
    "from llama_index.core.agent import ReActAgent\n",
    "image_retriever_tool = FunctionTool.from_defaults(fn=retriever_custom, description=\"Agent that will interpretate ikea manuals, so will be usefull for answer question related to that. You must pass the query and the main entity to the function tool. You must go and call the function always to get the images from the documents. If you not have results, maybe call first get_product_list_tool\")\n",
    "get_product_list_tool = FunctionTool.from_defaults(fn=get_product_list, description=\"Tool that provide list of products and names in the storage, usefull when user mistake with the name or you can't find the product\")\n",
    "llm = OpenAI(model=\"gpt-3.5-turbo\")\n",
    "agent = ReActAgent.from_tools([image_retriever_tool, get_product_list_tool], llm=llm, verbose=True,\n",
    "                              system_prompt =f\"\"\" \n",
    "                              Agent that will answer general question regarding ikea manuals, \n",
    "                              not use any prior knowledge, only answer from documents or other agents. \n",
    "                              First call get_product_list_tool tool to check if the user is asking about an product of the list.\n",
    "                              If you dont find a product item by the query, you can go to check the list of products using your tools and then figure the item, but if you think as a typo error, but if is completely different product that is not in the list, you can ask to the user that you don't have that item. \n",
    "                              If you can't answer, ask more information to the user.\n",
    "                              Always try to figure out if the user wanted to answer about a product on the list, so if he mistake with the name of the product try to figure out wich ones he wants using the get_product_list_tool.\n",
    "                              Always answer in the language the main user talk to you initially\n",
    "                              \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2fa9e1ba-8d70-4ce2-9d5b-feb280540535",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Running step 8283efd9-7e46-4799-b9f7-27ff183235e9. Step input: What is step 4 of assembling the Tuffing\n",
      "\u001b[1;3;38;5;200mThought: The current language of the user is: English. I need to use a tool to help me answer the question.\n",
      "Action: retriever_custom\n",
      "Action Input: {'query': 'What is step 4 of assembling the Tuffing', 'filter_entinty': 'tuffing', 'return_images': False}\n",
      "\u001b[0m\u001b[1;3;34mObservation: (CompletionResponse(text='In step 4 of assembling the Tuffing, you need to attach two screws to secure the fabric panel between two horizontal poles. Make sure the fabric is stretched evenly and the screws are tightened properly.', additional_kwargs={}, raw=ChatCompletion(id='chatcmpl-ANH9Rl4K2II2WTOJhK7zwTPIf5prQ', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='In step 4 of assembling the Tuffing, you need to attach two screws to secure the fabric panel between two horizontal poles. Make sure the fabric is stretched evenly and the screws are tightened properly.', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None))], created=1730110837, model='gpt-4o-2024-08-06', object='chat.completion', service_tier=None, system_fingerprint='fp_72bbfa6014', usage=CompletionUsage(completion_tokens=41, prompt_tokens=868, total_tokens=909, completion_tokens_details=CompletionTokensDetails(audio_tokens=None, reasoning_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=None, cached_tokens=0))), logprobs=None, delta=None), [])\n",
      "\u001b[0m> Running step 8f519300-c491-45a8-9622-87ba9f4724a5. Step input: None\n",
      "\u001b[1;3;38;5;200mThought: I can answer without using any more tools. I'll use the user's language to answer\n",
      "Answer: In step 4 of assembling the Tuffing, you need to attach two screws to secure the fabric panel between two horizontal poles. Make sure the fabric is stretched evenly and the screws are tightened properly.\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "response = agent.chat(\"What is step 4 of assembling the Tuffing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "34a7738f-0eb5-40dc-aca5-eaff6d44a872",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In step 4 of assembling the Tuffing, you need to attach two screws to secure the fabric panel between two horizontal poles. Make sure the fabric is stretched evenly and the screws are tightened properly.\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3e0e5c01-ae0d-4150-a8ef-4369063880d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_documents_chunks = [\n",
    "    {\n",
    "        \"item_folder\": \"smagoera-wardrobe-white__AA-2177175-4-100\",\n",
    "        \"pages\": list(range(6, 32)),\n",
    "        \"question\": \"Give a step-by-step instruction guide on how to assemble the Smagoera.\",\n",
    "    },\n",
    "    {\n",
    "        \"item_folder\": \"tuffing-bunk-bed-frame-dark-grey__AA-1627840-10-2\",\n",
    "        \"pages\": [1, 35],\n",
    "        \"question\": \"What does the Tuffing look like?\",\n",
    "    },\n",
    "    {\n",
    "        \"item_folder\": \"fredde-gaming-desk-black__AA-2508156-1-100\",\n",
    "        \"pages\": [3],\n",
    "        \"question\": \"What parts are included in the Fredde?\",\n",
    "    },\n",
    "    {\n",
    "        \"item_folder\": \"tuffing-bunk-bed-frame-dark-grey__AA-1627840-10-2\",\n",
    "        \"pages\": [8],\n",
    "        \"question\": \"What is step 4 of assembling the Tuffing?\",\n",
    "    },\n",
    "]\n",
    "\n",
    "def generate_correct_answers():\n",
    "    for tests in image_documents_chunks:\n",
    "        image_documents = [\n",
    "            ImageDocument(\n",
    "                image_path=f\"{store_path}/temp/{tests['item_folder']}/{tests['item_folder']}_{page}.png\"\n",
    "            )\n",
    "            for page in tests[\"pages\"]\n",
    "        ]\n",
    "        response = engine.llm.complete(\n",
    "            prompt=tests[\"question\"],\n",
    "            image_documents=image_documents,\n",
    "            temperature=0.0,\n",
    "        )\n",
    "        tests[\"response\"] = response\n",
    "    return image_documents_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9b598126-3ba0-4f38-85e9-29df3a4e7862",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'item_folder': 'smagoera-wardrobe-white__AA-2177175-4-100',\n",
       "  'pages': [6,\n",
       "   7,\n",
       "   8,\n",
       "   9,\n",
       "   10,\n",
       "   11,\n",
       "   12,\n",
       "   13,\n",
       "   14,\n",
       "   15,\n",
       "   16,\n",
       "   17,\n",
       "   18,\n",
       "   19,\n",
       "   20,\n",
       "   21,\n",
       "   22,\n",
       "   23,\n",
       "   24,\n",
       "   25,\n",
       "   26,\n",
       "   27,\n",
       "   28,\n",
       "   29,\n",
       "   30,\n",
       "   31],\n",
       "  'question': 'Give a step-by-step instruction guide on how to assemble the Smagoera.',\n",
       "  'response': CompletionResponse(text='### Assembly Guide for Smagoera\\n\\n#### Tools Required:\\n- Phillips screwdriver\\n- Flathead screwdriver\\n- Hammer\\n- Drill with 8 mm (5/16\") and 3 mm (1/8\") bits\\n\\n#### Step-by-Step Instructions:\\n\\n1. **Preparation:**\\n   - Ensure you have all the parts and tools ready.\\n   - Lay out all pieces and hardware.\\n\\n2. **Base Assembly:**\\n   - Attach 10 screws to the two base panels using the provided hardware.\\n\\n3. **Side Panel Assembly:**\\n   - Insert the wooden dowels into the side panels.\\n   - Secure with screws as shown.\\n\\n4. **Back Panel Installation:**\\n   - Attach the back panel to the base using screws and dowels.\\n\\n5. **Top Panel Installation:**\\n   - Place the top panel onto the structure and secure with screws.\\n\\n6. **Bracket Installation:**\\n   - Attach the brackets to the inside of the structure for additional support.\\n\\n7. **Door Assembly:**\\n   - Attach hinges to the doors using the provided screws.\\n   - Install the doors onto the main structure.\\n\\n8. **Final Adjustments:**\\n   - Ensure all screws are tightened.\\n   - Adjust the doors for proper alignment.\\n\\n9. **Wall Mounting:**\\n   - Use the provided wall brackets and screws to secure the unit to the wall.\\n   - Drill holes as needed using the 8 mm and 3 mm drill bits.\\n\\n10. **Finishing Touch', additional_kwargs={}, raw=ChatCompletion(id='chatcmpl-ANH9kLfbxyspWMq7AVg0BaP6T6vXR', choices=[Choice(finish_reason='length', index=0, logprobs=None, message=ChatCompletionMessage(content='### Assembly Guide for Smagoera\\n\\n#### Tools Required:\\n- Phillips screwdriver\\n- Flathead screwdriver\\n- Hammer\\n- Drill with 8 mm (5/16\") and 3 mm (1/8\") bits\\n\\n#### Step-by-Step Instructions:\\n\\n1. **Preparation:**\\n   - Ensure you have all the parts and tools ready.\\n   - Lay out all pieces and hardware.\\n\\n2. **Base Assembly:**\\n   - Attach 10 screws to the two base panels using the provided hardware.\\n\\n3. **Side Panel Assembly:**\\n   - Insert the wooden dowels into the side panels.\\n   - Secure with screws as shown.\\n\\n4. **Back Panel Installation:**\\n   - Attach the back panel to the base using screws and dowels.\\n\\n5. **Top Panel Installation:**\\n   - Place the top panel onto the structure and secure with screws.\\n\\n6. **Bracket Installation:**\\n   - Attach the brackets to the inside of the structure for additional support.\\n\\n7. **Door Assembly:**\\n   - Attach hinges to the doors using the provided screws.\\n   - Install the doors onto the main structure.\\n\\n8. **Final Adjustments:**\\n   - Ensure all screws are tightened.\\n   - Adjust the doors for proper alignment.\\n\\n9. **Wall Mounting:**\\n   - Use the provided wall brackets and screws to secure the unit to the wall.\\n   - Drill holes as needed using the 8 mm and 3 mm drill bits.\\n\\n10. **Finishing Touch', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None))], created=1730110856, model='gpt-4o-2024-08-06', object='chat.completion', service_tier=None, system_fingerprint='fp_72bbfa6014', usage=CompletionUsage(completion_tokens=300, prompt_tokens=2233, total_tokens=2533, completion_tokens_details=CompletionTokensDetails(audio_tokens=None, reasoning_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=None, cached_tokens=0))), logprobs=None, delta=None)},\n",
       " {'item_folder': 'tuffing-bunk-bed-frame-dark-grey__AA-1627840-10-2',\n",
       "  'pages': [1, 35],\n",
       "  'question': 'What does the Tuffing look like?',\n",
       "  'response': CompletionResponse(text='The Tuffing is a bunk bed with a minimalist design. It features a metal frame with guardrails on the top bunk for safety. The bed has a ladder for access to the upper bunk, and the overall structure is sturdy and functional, suitable for small spaces.', additional_kwargs={}, raw=ChatCompletion(id='chatcmpl-ANH9s7FmoG32fJAJvxCBuTD8ZLSNU', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='The Tuffing is a bunk bed with a minimalist design. It features a metal frame with guardrails on the top bunk for safety. The bed has a ladder for access to the upper bunk, and the overall structure is sturdy and functional, suitable for small spaces.', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None))], created=1730110864, model='gpt-4o-2024-08-06', object='chat.completion', service_tier=None, system_fingerprint='fp_72bbfa6014', usage=CompletionUsage(completion_tokens=54, prompt_tokens=186, total_tokens=240, completion_tokens_details=CompletionTokensDetails(audio_tokens=None, reasoning_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=None, cached_tokens=0))), logprobs=None, delta=None)},\n",
       " {'item_folder': 'fredde-gaming-desk-black__AA-2508156-1-100',\n",
       "  'pages': [3],\n",
       "  'question': 'What parts are included in the Fredde?',\n",
       "  'response': CompletionResponse(text='The parts included in the Fredde are:\\n\\n- 2 long screws\\n- 6 medium screws\\n- 5 short screws\\n- 12 dowels\\n- 4 cylindrical spacers\\n- 4 small screws\\n- 2 small bolts\\n- 4 rectangular pads\\n- 2 metal brackets\\n- 2 round caps\\n- 12 small dowels\\n- 17 small cylindrical spacers\\n- 4 oval pads\\n- 2 Allen wrenches\\n- 2 large circular rings\\n- 2 medium circular rings\\n\\nThese components are used for assembly.', additional_kwargs={}, raw=ChatCompletion(id='chatcmpl-ANH9teRWvQcU4a4ZrT2Bqi5TxU36i', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='The parts included in the Fredde are:\\n\\n- 2 long screws\\n- 6 medium screws\\n- 5 short screws\\n- 12 dowels\\n- 4 cylindrical spacers\\n- 4 small screws\\n- 2 small bolts\\n- 4 rectangular pads\\n- 2 metal brackets\\n- 2 round caps\\n- 12 small dowels\\n- 17 small cylindrical spacers\\n- 4 oval pads\\n- 2 Allen wrenches\\n- 2 large circular rings\\n- 2 medium circular rings\\n\\nThese components are used for assembly.', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None))], created=1730110865, model='gpt-4o-2024-08-06', object='chat.completion', service_tier=None, system_fingerprint='fp_72bbfa6014', usage=CompletionUsage(completion_tokens=120, prompt_tokens=101, total_tokens=221, completion_tokens_details=CompletionTokensDetails(audio_tokens=None, reasoning_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=None, cached_tokens=0))), logprobs=None, delta=None)},\n",
       " {'item_folder': 'tuffing-bunk-bed-frame-dark-grey__AA-1627840-10-2',\n",
       "  'pages': [8],\n",
       "  'question': 'What is step 4 of assembling the Tuffing?',\n",
       "  'response': CompletionResponse(text='In step 4 of assembling the Tuffing, you need to attach two screws (labeled 114002) to secure the fabric piece onto the frame.', additional_kwargs={}, raw=ChatCompletion(id='chatcmpl-ANH9wI3VL5tAn3BPPsXobdCPxlAXE', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='In step 4 of assembling the Tuffing, you need to attach two screws (labeled 114002) to secure the fabric piece onto the frame.', refusal=None, role='assistant', audio=None, function_call=None, tool_calls=None))], created=1730110868, model='gpt-4o-2024-08-06', object='chat.completion', service_tier=None, system_fingerprint='fp_72bbfa6014', usage=CompletionUsage(completion_tokens=33, prompt_tokens=104, total_tokens=137, completion_tokens_details=CompletionTokensDetails(audio_tokens=None, reasoning_tokens=0), prompt_tokens_details=PromptTokensDetails(audio_tokens=None, cached_tokens=0))), logprobs=None, delta=None)}]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_correct_answers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2347dc7a-4afd-4f4e-ad17-3152ecd0e4af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_eval_answers():\n",
    "    for tests in image_documents_chunks:\n",
    "        mssg = extract_keyword_from_query(tests[\"question\"])\n",
    "        item = str(mssg).split(\":\")[-1].strip().lower()\n",
    "        response, images = retriever_custom(tests[\"question\"], item, True)\n",
    "\n",
    "        source_image_nodes = [\n",
    "            score_img_node.node.metadata[\"file_path\"]\n",
    "            for score_img_node in images\n",
    "        ]\n",
    "        context = [\n",
    "            score_img_node.node.metadata[\"item\"]\n",
    "            for score_img_node in images\n",
    "        ]\n",
    "        \n",
    "        tests[\"predict\"] = response\n",
    "        tests[\"images\"] = source_image_nodes\n",
    "        tests[\"context\"] = context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1d051087-7a67-4ab3-8b5f-3a500f09b3d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;3;38;2;155;135;227m> Running module adf58ca9-51c8-4f63-830a-02fbfe3bce67 with input: \n",
      "question: Give a step-by-step instruction guide on how to assemble the Smagoera.\n",
      "\n",
      "\u001b[0m\u001b[1;3;38;2;155;135;227m> Running module 2ddf6e18-b2b0-4442-8518-2af2dd4ce881 with input: \n",
      "messages:         Please extract the entity that que question is referencing: Give a step-by-step instruction guide on how to assemble the Smagoera..  Retrieve only the single word of in \"minus\", the item brand...\n",
      "\n",
      "\u001b[0m\u001b[1;3;38;2;155;135;227m> Running module 10c01d6c-7686-45dc-a5af-f8fa8dfdf925 with input: \n",
      "question: What does the Tuffing look like?\n",
      "\n",
      "\u001b[0m\u001b[1;3;38;2;155;135;227m> Running module 5be1bfee-3f80-4ba6-acac-c4c65c9e6545 with input: \n",
      "messages:         Please extract the entity that que question is referencing: What does the Tuffing look like?.  Retrieve only the single word of in \"minus\", the item brand, like 'fredy' or 'tuffing'. \n",
      "    \n",
      "\n",
      "\u001b[0m\u001b[1;3;38;2;155;135;227m> Running module f516440c-9cda-4d57-a0b9-1c9e1c0ef79c with input: \n",
      "question: What parts are included in the Fredde?\n",
      "\n",
      "\u001b[0m\u001b[1;3;38;2;155;135;227m> Running module 3e18cccf-9360-4820-ad36-f55f65ed15a6 with input: \n",
      "messages:         Please extract the entity that que question is referencing: What parts are included in the Fredde?.  Retrieve only the single word of in \"minus\", the item brand, like 'fredy' or 'tuffing'. \n",
      "  ...\n",
      "\n",
      "\u001b[0m\u001b[1;3;38;2;155;135;227m> Running module 22723299-ae6a-4140-9efd-209e883b4b10 with input: \n",
      "question: What is step 4 of assembling the Tuffing?\n",
      "\n",
      "\u001b[0m\u001b[1;3;38;2;155;135;227m> Running module 531fa73e-4420-41b9-8f16-abaac203dc06 with input: \n",
      "messages:         Please extract the entity that que question is referencing: What is step 4 of assembling the Tuffing?.  Retrieve only the single word of in \"minus\", the item brand, like 'fredy' or 'tuffing'. ...\n",
      "\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "generate_eval_answers()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b7937524-c8ab-4e3d-ac20-5f464174060d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.core.evaluation import CorrectnessEvaluator\n",
    "from llama_index.core.evaluation.multi_modal import (\n",
    "    MultiModalRelevancyEvaluator,\n",
    "    MultiModalFaithfulnessEvaluator,\n",
    ")\n",
    "\n",
    "import os\n",
    "\n",
    "judges = {}\n",
    "\n",
    "judges[\"correctness\"] = CorrectnessEvaluator(\n",
    "    llm=OpenAI(temperature=0, model=\"gpt-4\"),\n",
    ")\n",
    "\n",
    "judges[\"relevancy\"] = MultiModalRelevancyEvaluator(\n",
    "    multi_modal_llm=OpenAIMultiModal(\n",
    "        model=\"gpt-4o\",\n",
    "        max_new_tokens=300,\n",
    "    )\n",
    ")\n",
    "\n",
    "judges[\"faithfulness\"] = MultiModalFaithfulnessEvaluator(\n",
    "    multi_modal_llm=OpenAIMultiModal(\n",
    "        model=\"gpt-4o\",\n",
    "        max_new_tokens=300,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd57bae0-b287-4750-81df-6945ef9d63fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "evals = {\n",
    "    \"names\": list(range(1, 5)),\n",
    "    \"correctness\": [],\n",
    "    \"relevancy\": [],\n",
    "    \"faithfulness\": [],\n",
    "}\n",
    "\n",
    "for data_entry in image_documents_chunks:\n",
    "    batch_names = []\n",
    "    batch_correctness = []\n",
    "    batch_relevancy = []\n",
    "    batch_faithfulness = []\n",
    "    correctness_result = await judges[\"correctness\"].aevaluate(\n",
    "        query=data_entry[\"question\"],\n",
    "        response=data_entry[\"predict\"].text,\n",
    "        reference=data_entry['response'].text,\n",
    "    )\n",
    "\n",
    "    relevancy_result = judges[\"relevancy\"].evaluate(\n",
    "        query=data_entry[\"question\"],\n",
    "        response=data_entry[\"predict\"].text,\n",
    "        contexts=data_entry[\"context\"],\n",
    "        image_paths=data_entry[\"images\"],\n",
    "    )\n",
    "\n",
    "    faithfulness_result = judges[\"faithfulness\"].evaluate(\n",
    "        query=data_entry[\"question\"],\n",
    "        response=data_entry[\"predict\"].text,\n",
    "        contexts=data_entry[\"context\"],\n",
    "        image_paths=data_entry[\"images\"],\n",
    "    )\n",
    "    batch_correctness.append(correctness_result)\n",
    "    batch_relevancy.append(relevancy_result)\n",
    "    batch_faithfulness.append(faithfulness_result)\n",
    "\n",
    "    evals[\"correctness\"] += batch_correctness\n",
    "    evals[\"relevancy\"] += batch_relevancy\n",
    "    evals[\"faithfulness\"] += batch_faithfulness\n",
    "\n",
    "# save evaluations\n",
    "evaluations_objects = {\n",
    "    \"names\": list(range(1, 5)),\n",
    "    \"correctness\": [e.dict() for e in evals[\"correctness\"]],\n",
    "    \"faithfulness\": [e.dict() for e in evals[\"faithfulness\"]],\n",
    "    \"relevancy\": [e.dict() for e in evals[\"relevancy\"]],\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c68549bc-f275-4349-a5a3-daa3568d38c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluations_objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7006c0e-d42e-4dbc-925c-c0fff0c1a221",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.evaluation.notebook_utils import get_eval_results_df\n",
    "import pandas as pd\n",
    "\n",
    "deep_eval_df, mean_correctness_df = get_eval_results_df(\n",
    "   list(range(1, 5)), evals[\"correctness\"], metric=\"correctness\"\n",
    ")\n",
    "_, mean_relevancy_df = get_eval_results_df(\n",
    "    list(range(1, 5)), evals[\"relevancy\"], metric=\"relevancy\"\n",
    ")\n",
    "_, mean_faithfulness_df = get_eval_results_df(\n",
    "    list(range(1, 5)), evals[\"faithfulness\"], metric=\"faithfulness\"\n",
    ")\n",
    "\n",
    "mean_scores_df = pd.concat(\n",
    "    [\n",
    "        mean_correctness_df.reset_index(),\n",
    "        mean_relevancy_df.reset_index(),\n",
    "        mean_faithfulness_df.reset_index(),\n",
    "    ],\n",
    "    axis=0,\n",
    "    ignore_index=True,\n",
    ")\n",
    "mean_scores_df = mean_scores_df.set_index(\"index\")\n",
    "mean_scores_df.index = mean_scores_df.index.set_names([\"metrics\"])\n",
    "mean_scores_df.index.name = 'sample' \n",
    "mean_scores_df = mean_scores_df.rename(index={'rag': 'samples'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb0d0572-038a-42d5-8d8e-a6898fc63559",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_scores_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5d16151-f31a-407f-8a9c-4adba7feeac1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
